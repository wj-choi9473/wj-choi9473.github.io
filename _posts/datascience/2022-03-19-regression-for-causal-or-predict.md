---
title: "[Causal Inference] 인과추론 관점에서 회귀분석"
categories: 
  - Data Science
tags:
  - Essay
  - Causal Inference

toc: false

last_modified_at: 2022-03-19
redirect_from:
    - /Data Science/인과추론 관점에서 회귀분석

---

회귀분석은 인과추론을 위한 목적과 예측을 위한 목적으로 모두 쓰일 수 있기에, 많이 헷갈려 하는 경우도 있어 보입니다. 저도 그랬고 많이들 가질 수 있는 의문은  $R^2$ 값이 이렇게 낮은데 뭐지? 하는 의문입니다. 하지만 이는 그렇게 간단하게 판단할 일이 아닐 수 있습니다.
회귀 분석시 예측을 위한 지표(e.g. $R^2$)로 인과관계 모델을 평가 하지 않습니다.

두 방법론의 가장 큰 차이는 분석 목적의 차이입니다.

(1) 선행변수에 대한 개입 vs. 후행변수에 대한 예측  
(2) 편향 (Bias) 최소화 vs. 편향 + 변동성 (Variance) 최소화  
(3) 내적 타당성 (in-sample 비편향 추정) 최대화 vs. 외적 타당성 (out-of-sample 예측) 최대화  

이러한 목적의 차이는 수식에서 나타난다기 보다는, 모델에 대한 평가 방법이나 평가 기준에서 차이가 나게 됩니다. 인과추론을 위해서는 편향이 얼마나 최소화 되었는지, 내적 타당성을 위한 "연구 디자인" (실험 설계/준실험 방법 등)이 적절하게 활용되고 있는지가 가장 중요한 평가의 척도입니다. 

(편향 최소화에 대해서 완벽하게 평가할 수 있는 방법은 없기에, 다양한 간접적인 근거와 논리를 통해 종합적으로 평가합니다)

반면, 머신러닝에서는 손실 함수의 도입을 통해 변동성이 클수록 손실을 크게 정의함으로써 손실을 최소화하는 방향으로 수식을 학습하게 될 것입니다. 가장 대표적으로 회귀분석을 통한 예측을 위해서 LASSO 나 Ridge Regression 등이 있습니다. 하지만, 이러한 회귀분석은 인과추론에는 적절하지 않은데, 그 이유는 이들의 `수식` 때문이 아닌, 통계적으로 추정하거나 데이터를 통해 학습하는 방법이 인과추론의 `목적` 에 부합하지 않기 때문입니다.

좀 더 개념적으로 설명을 드리자면

보통 outcome이 treatment와 여러 covariates로 나오는 function을

$Y = F(x,t)$ 라고 쓰겠습니다.

이 fuction을 두가지 요소로 나눌 수 있다고 하겠습니다, 한 요소는 treatment와 상관이 없는 요소고 다른 요소는 treatment에만 상관 있는, interaction이 있는 요소 입니다.

$Y = g(x) + f(t,x)$

이러한 방식이 Data Generating Process (DGP)를 표현합니다. 즉, 어떤 데이터인지, 데이터가 어떻게 생성되는지에 대한 사고방식이자 논리라고 보시면 될 거 같습니다.

중요한 점은 treatment effect가 다른 covariates의 효과 보다 낮다면, 예측력은 높지만 인과적 추론에는 좋지 않은 모형일 수 있다는 점 입니다. 모델이 $g(x)$에 의존하여 만들 수 있기 때문입니다. 다시 말해서, 인과추론 관점에서는 인과관계를 밝히기에 얼마나 좋은지 알 수가 없습니다.

3줄 요약

예측, 인과추론 둘다 중요하고 답할 수 있는 문제가 조금 다름!

예측 → 고객들이 이탈을 할까?  $\hat y$ 추정

인과추론 → 할인쿠폰을 줬을 때 고객이 이탈을 얼마나 덜 할까? 각 변수들의(또는 원하는 변수) $\hat\beta$ 를 추정